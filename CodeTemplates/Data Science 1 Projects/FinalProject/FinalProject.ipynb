{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\FinalProject\\FinalProject.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/OneDrive/Desktop/GitHub%20Repositories/DataScience1/CodeTemplates/Data%20Science%201%20Projects/FinalProject/FinalProject.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/OneDrive/Desktop/GitHub%20Repositories/DataScience1/CodeTemplates/Data%20Science%201%20Projects/FinalProject/FinalProject.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Download the NLTK stop words if not already downloaded\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/OneDrive/Desktop/GitHub%20Repositories/DataScience1/CodeTemplates/Data%20Science%201%20Projects/FinalProject/FinalProject.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import string\n",
    "df = pd.read_csv(\"chat_data.csv\")\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "# Download the NLTK stop words if not already downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"chat_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Convert the 'text' column to string type\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Split the text into lists of words\n",
    "df['text'] = df['text'].str.split()\n",
    "\n",
    "# Initialize an empty list to store words with their indices\n",
    "word_list = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    words = row['text']\n",
    "    for word in words:\n",
    "        word_list.append(f\"{idx}: {word}\")\n",
    "\n",
    "# Convert the list of words to a DataFrame\n",
    "word_df = pd.DataFrame({'word': word_list})\n",
    "\n",
    "# Access individual words by index\n",
    "print(word_df['word'][0])  # Output: \"0: I'm\"\n",
    "print(word_df['word'][1000])  # Output: \"0: considering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Combine all words into a single list\n",
    "all_words = [word.split(\":\")[1] for word in word_df['word']]\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Print the word counts\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"'{word}': {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Combine all words into a single list\n",
    "all_words = [word.split(\":\")[1] for word in word_df['word']]\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Get the top 50 most common words\n",
    "top_50_words = word_counts.most_common(50)\n",
    "\n",
    "# Create a DataFrame for the top 50 words\n",
    "top_50_df = pd.DataFrame(top_50_words, columns=['Word', 'Count'])\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_50_df, x='Count', y='Word', palette='viridis')\n",
    "plt.xlabel('Count', fontsize=14)\n",
    "plt.ylabel('Word', fontsize=14)\n",
    "plt.title('Top 50 Most Common Words', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Function to create and display a grouped bar plot\n",
    "def create_grouped_bar_plot(data, x, y, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=data, x=x, y=y, hue='Sentiment', palette='viridis')\n",
    "    plt.xlabel('Word', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xticks(fontsize=12, rotation=45)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(title='Sentiment', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store word counts for '0' and '1' sentiments\n",
    "word_counts_0 = []\n",
    "word_counts_1 = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    words = re.findall(r'\\w+', text)  # Split the text into words using regex\n",
    "    sentiment = int(row['class'])\n",
    "    if sentiment == 0:\n",
    "        word_counts_0.extend(words)\n",
    "    elif sentiment == 1:\n",
    "        word_counts_1.extend(words)\n",
    "\n",
    "# Count the occurrences of words for both '0' and '1' sentiments\n",
    "word_counts_0 = pd.Series(word_counts_0).value_counts()\n",
    "word_counts_1 = pd.Series(word_counts_1).value_counts()\n",
    "\n",
    "# Combine the counts into a single DataFrame\n",
    "word_counts_combined = pd.DataFrame({\n",
    "    'Word': word_counts_0.index,\n",
    "    'Count': word_counts_0.values,\n",
    "    'Sentiment': '0',\n",
    "})\n",
    "\n",
    "# Add the counts for '1' sentiment\n",
    "word_counts_combined = word_counts_combined.append(pd.DataFrame({\n",
    "    'Word': word_counts_1.index,\n",
    "    'Count': word_counts_1.values,\n",
    "    'Sentiment': '1',\n",
    "}))\n",
    "\n",
    "# Sort by total count\n",
    "word_counts_combined = word_counts_combined.sort_values(by='Count', ascending=False).head(50)\n",
    "\n",
    "# Create a grouped bar plot with two bars for each word\n",
    "create_grouped_bar_plot(word_counts_combined, x='Word', y='Count', title='Top 50 Most Common Words with Sentiment Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\tyler\\OneDrive\\Desktop\\GitHub Repositories\\DataScience1\\CodeTemplates\\Data Science 1 Projects\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize lists to store word counts for '0' and '1' sentiments\n",
    "word_counts_0 = []\n",
    "word_counts_1 = []\n",
    "\n",
    "# Get the list of NLTK stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    words = re.findall(r'\\w+', text)  # Split the text into words using regex\n",
    "    sentiment = int(row['class'])\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]  # Filter out stop words\n",
    "    if sentiment == 0:\n",
    "        word_counts_0.extend(words)\n",
    "    elif sentiment == 1:\n",
    "        word_counts_1.extend(words)\n",
    "\n",
    "# Count the occurrences of words for both '0' and '1' sentiments\n",
    "word_counts_0 = pd.Series(word_counts_0).value_counts()\n",
    "word_counts_1 = pd.Series(word_counts_1).value_counts()\n",
    "\n",
    "# Combine the counts into a single DataFrame\n",
    "word_counts_combined = pd.DataFrame({\n",
    "    'Word': word_counts_0.index,\n",
    "    'Count': word_counts_0.values,\n",
    "    'Sentiment': '0',\n",
    "})\n",
    "\n",
    "# Add the counts for '1' sentiment\n",
    "word_counts_combined = word_counts_combined.append(pd.DataFrame({\n",
    "    'Word': word_counts_1.index,\n",
    "    'Count': word_counts_1.values,\n",
    "    'Sentiment': '1',\n",
    "}))\n",
    "\n",
    "# Sort by total count\n",
    "word_counts_combined = word_counts_combined.sort_values(by='Count', ascending=False).head(50)\n",
    "\n",
    "# Create a grouped bar plot with two bars for each word\n",
    "create_grouped_bar_plot(word_counts_combined, x='Word', y='Count', title='Top 50 Most Common Words with Sentiment Counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
